{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6ce65bf39cc2004",
   "metadata": {},
   "source": [
    "# Using AI Verde\n",
    "## required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0c067cc60486232",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T01:28:05.864596Z",
     "start_time": "2024-07-31T01:28:05.860056Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from docling.document_converter import DocumentConverter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db67bd9-8ee9-47b4-ab1e-f2990eca1356",
   "metadata": {},
   "source": [
    "# Step 0\n",
    "\n",
    "In order to gain access to AI Verde at chat.cyverse.ai, email verde-support@cyverse.org with your information and how you'd like to use AI-Verde.\n",
    "\n",
    "## Getting your API Key\n",
    "### Visit chat.cyverse.ai and login with your netid\n",
    "After logging in, click the Details button on a course you're enrolled in:\n",
    "\n",
    "![details](./images/verde-api-key-1.png)\n",
    "\n",
    "Use the API key to access AI-Verde's API programmatically:\n",
    "\n",
    "![apikey](./images/verde-api-key-2.png)\n",
    "\n",
    "Visit https://aiverde-docs.cyverse.ai/ for documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764cff2b916d895a",
   "metadata": {},
   "source": [
    "## Step 1 - Set up the environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T01:28:05.869113Z",
     "start_time": "2024-07-31T01:28:05.865773Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import the API keys from the environment\n",
    "llm_host = os.environ.get('OPENAI_API_BASE')\n",
    "api_key = os.environ.get('OPENAI_API_KEY')\n",
    "model_name = \"Meta-Llama-3.1-70B-Instruct-quantized\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b180e29096fce451",
   "metadata": {},
   "source": [
    "## Step 2 - directly use LangChain ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb18a0c755604bbf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T01:28:07.852877Z",
     "start_time": "2024-07-31T01:28:05.869801Z"
    }
   },
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model=model_name,\n",
    "    temperature=0,\n",
    "    api_key=api_key,\n",
    "    base_url=llm_host,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "387d71eb2ee3768d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T01:28:08.934821Z",
     "start_time": "2024-07-31T01:28:07.853490Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Desert sunset fades\n",
      "Santa Catalinas rise\n",
      "Golden peaceful night\n"
     ]
    }
   ],
   "source": [
    "message = llm.invoke(\"Compose a haiku about the beauty of Tucson\")\n",
    "print(message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88fcfc4cdd3ad9bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T01:28:19.762053Z",
     "start_time": "2024-07-31T01:28:08.937416Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'token_usage': {'completion_tokens': 14, 'prompt_tokens': 44, 'total_tokens': 58, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'neuralmagic/Meta-Llama-3.1-70B-Instruct-quantized.w8a8', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}\n"
     ]
    }
   ],
   "source": [
    "# show message metadata including token consumption\n",
    "print(message.response_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60290fcb0d80b841",
   "metadata": {},
   "source": [
    "## Demo - Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a174cb81053c8f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T01:28:26.705721Z",
     "start_time": "2024-07-31T01:28:19.765039Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not load the custom kernel for multi-scale deformable attention: /home/neddy/.cache/torch_extensions/py312_cu124/MultiScaleDeformableAttention/MultiScaleDeformableAttention.so: cannot open shared object file: No such file or directory\n",
      "Could not load the custom kernel for multi-scale deformable attention: /home/neddy/.cache/torch_extensions/py312_cu124/MultiScaleDeformableAttention/MultiScaleDeformableAttention.so: cannot open shared object file: No such file or directory\n",
      "Could not load the custom kernel for multi-scale deformable attention: /home/neddy/.cache/torch_extensions/py312_cu124/MultiScaleDeformableAttention/MultiScaleDeformableAttention.so: cannot open shared object file: No such file or directory\n",
      "Could not load the custom kernel for multi-scale deformable attention: /home/neddy/.cache/torch_extensions/py312_cu124/MultiScaleDeformableAttention/MultiScaleDeformableAttention.so: cannot open shared object file: No such file or directory\n",
      "Could not load the custom kernel for multi-scale deformable attention: /home/neddy/.cache/torch_extensions/py312_cu124/MultiScaleDeformableAttention/MultiScaleDeformableAttention.so: cannot open shared object file: No such file or directory\n",
      "Could not load the custom kernel for multi-scale deformable attention: /home/neddy/.cache/torch_extensions/py312_cu124/MultiScaleDeformableAttention/MultiScaleDeformableAttention.so: cannot open shared object file: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Automatic Learning for Multilingual Temporal Recognition based on TiMBL\n",
      "\n",
      "Marcel Puchol-Blasco, Estela Saquete, Patricio Martínez-Barco\n",
      "Department of Languages and Information Systems (University of Alicante)\n",
      "Carretera San Vicente s/n, 03690 Alicante, Spain\n",
      "{marcel,stela,patricio@dlsi.ua.es}\n",
      "\n",
      "Abstract:\n",
      "This article presents a system based on automatic learning for the recognition of temporal expressions. The system uses the TiMBL application, which is a memory-based machine learning system. The portability of this system to other new languages has a very low cost, as it does not require any language-dependent resources (only requires a tokenizer and a lexical disambiguator, although the lack of a POS tagger does not significantly affect the final system results). This system has been evaluated for three different languages: English, Spanish, and Italian. The evaluation results are quite successful for corpora with a large number of examples, while it obtains very poor results with corpora that have only a few examples.\n",
      "\n",
      "Keywords: temporal information, temporal expression recognition, machine learning\n",
      "\n",
      "## 1. Introduction\n",
      "\n",
      "The recognition of temporal expressions is becoming increasingly important as a task within the field of Natural Language Processing (NLP). The reason for its importance lies in the fact that it is a previous step to the resolution of temporal expressions, a task that can be used in other areas of NLP such as Temporal Question Answering, the realization of summaries, the ordering of events, etc.\n",
      "\n",
      "As in almost all aspects of NLP, there are two approaches to the recognition of temporal expressions: systems based on knowledge or rules and systems based on automatic learning (AA).\n",
      "\n",
      "One of the most important characteristics that current NLP systems must present is the ease of adaptation to new languages. In this aspect, rule-based systems have a great disadvantage, as the entire set of rules must be rewritten and adapted to the new language to be treated. However, AA methods present a great advantage in this aspect, as the adaptation to other languages requires a lower cost than that of rule-based systems, since, in the case of wanting to adapt several rule-based systems, each of the knowledge bases of these systems must be adapted, while if several AA systems are desired to be adapted, generating a single annotated corpus is usually sufficient to adapt them all. However, an important disadvantage of these systems lies in the need for an annotated corpus with temporal expressions in the new language to be treated, which is not always available.\n",
      "\n",
      "In previous publications, we have addressed the topic of adapting a temporal resolution system based on rules for Spanish (TERSEO, see Saquete, Muñoz, and Martínez-Barco (2005)), starting from the base of the translation of the rules through automatic translation methods.\n",
      "\n",
      "In line with improving the results obtained previously (89% F-measure for English and 79% F-measure for Italian), and taking into account the good results offered by AA systems presented in different competitions (such as the Time Expression Recognition and Normalization Workshop - TERN 2004), it has been decided to change the methodology used in some modules of TERSEO.\n",
      "\n",
      "In this article, we present the adaptation of the temporal expression recognition module used by TERSEO to AA methods. For this purpose, we have decided to use the TiMBL AA system (Daelemans, Zavrel, and van der Sloot, 2004).\n"
     ]
    }
   ],
   "source": [
    "# translate a research paper in Spanish into English\n",
    "# parse the PDF using Docling\n",
    "\n",
    "pdf_path = \"PLN_39_12.pdf\"\n",
    "converter = DocumentConverter()\n",
    "result = converter.convert(pdf_path)\n",
    "markdown = result.document.export_to_markdown()\n",
    "\n",
    "prompt = \"You are an expert document translator. Translate the given Markdown document into English. Do your best to correct apparent spelling and OCR issues, but do not insert words that were not in the original document.\"\n",
    "message = [\n",
    "    (\"system\", prompt),\n",
    "    (\"human\", markdown[:5000]),\n",
    "]\n",
    "result = llm.invoke(message)\n",
    "print(result.content)\n",
    "#print(len(markdown))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
